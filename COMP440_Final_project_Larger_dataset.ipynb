{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG_KpSM1FlQv"
   },
   "source": [
    "**What dataset are we working with?**\n",
    "\n",
    "https://www.kaggle.com/datasets/mathurinache/citation-network-dataset/data?select=dblp.v12.json\n",
    "\n",
    "How was the dataset collected?\n",
    "\n",
    "For what purpose was the dataset collected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN clean_data.py OR GET data.csv FROM GOOGLE DRIVE BEFORE RUNNING THIS NOTEBOOK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM1Ny3K_17q8"
   },
   "outputs": [],
   "source": [
    "citations_df = pd.read_csv('indexed_data_rory.csv')\n",
    "\n",
    "citations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1712635592248,
     "user": {
      "displayName": "Eddie Chen",
      "userId": "17886336257218875792"
     },
     "user_tz": 300
    },
    "id": "iCsTbU262Etg",
    "outputId": "b3bf988e-ef11-4c54-a076-d3719e7ccd29"
   },
   "outputs": [],
   "source": [
    "print(citations_df.columns)\n",
    "print(citations_df.shape)\n",
    "\n",
    "# Check for NA values\n",
    "print(citations_df[\"ID\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3,538,030 rows of data. Of these rows of data, all of them have an ID that is not NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(citations_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(citations_df.ID.isna().sum())\n",
    "print(citations_df.Title.isna().sum())\n",
    "print(citations_df.Year.isna().sum())\n",
    "print(citations_df.Citations.isna().sum())\n",
    "print(citations_df[\"Document Type\"].isna().sum())\n",
    "print(citations_df.Authors.isna().sum())\n",
    "print(citations_df.Venue.isna().sum())\n",
    "print(citations_df[\"Field of Study\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at this we saw that \"Document Type\" had 245,676 rows containing NA elements; \"Venue\" had 33,499 rows with NA, and \"Field of Study\" had 3,128 rows with NA. We will be dropping these so that we are working with complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_df = citations_df.dropna()\n",
    "print(citations_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 3,277,181 rows of data that have all their columns filled out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all IDs are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC60PhK33bNe"
   },
   "outputs": [],
   "source": [
    "# Check if all IDs are unique\n",
    "print(citations_df.shape[0])\n",
    "print(len(citations_df[\"ID\"].unique()))\n",
    "\n",
    "ids = set()\n",
    "repeatedIds = []\n",
    "\n",
    "for id in citations_df[\"ID\"]:\n",
    "  if id in ids:\n",
    "    repeatedIds.append(id)\n",
    "  else:\n",
    "    ids.add(id)\n",
    "\n",
    "print(\"This is num of repeated IDs: \" + str(len(repeatedIds)))\n",
    "print(\"These are the repeated IDs:\")\n",
    "print(repeatedIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no repeated IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uL_QtDmCVYV"
   },
   "outputs": [],
   "source": [
    "# These columns are Series data types\n",
    "print(citations_df.Year.min())\n",
    "print(citations_df.Year.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKFsXZ1qF9ze"
   },
   "source": [
    "There are no papers whose Year is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qc0Lo0y4JkUi"
   },
   "outputs": [],
   "source": [
    "# Papers written between 1800 (inclusive) and 1899 (inclusive)\n",
    "print(citations_df[(citations_df[\"Year\"] >= 1800) & (citations_df[\"Year\"] < 1900)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmclORhlLD-P"
   },
   "outputs": [],
   "source": [
    "# Papers written between 1900 (inclusive) and 1999 (inclusive)\n",
    "print(citations_df[(citations_df[\"Year\"] >= 1900) & (citations_df[\"Year\"] < 1999)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0DWl79hLSv_"
   },
   "outputs": [],
   "source": [
    "# Papers written past 2000 (inclusive)\n",
    "print(citations_df[(citations_df[\"Year\"] >= 2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13719,
     "status": "ok",
     "timestamp": 1712638784951,
     "user": {
      "displayName": "Eddie Chen",
      "userId": "17886336257218875792"
     },
     "user_tz": 300
    },
    "id": "GeZSJvuUL_5C",
    "outputId": "bebf4c6e-acc4-4500-f3d2-e399cf7bb1b3"
   },
   "outputs": [],
   "source": [
    "print(len(citations_df.Title.unique()))\n",
    "print(\"There are \" + str(citations_df.shape[0] - len(citations_df.Title.unique())) + \" papers that share the same title\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddkfkZvuOA-y"
   },
   "source": [
    "Of the 3,277,181 papers in the dataset, there are only 3,232,994 unique titles. This means that 44,187 papers share their title with another paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_df.loc[citations_df[citations_df[\"Citations\"] >= citations_df.Citations.max()].index[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1712639760886,
     "user": {
      "displayName": "Eddie Chen",
      "userId": "17886336257218875792"
     },
     "user_tz": 300
    },
    "id": "4_1Ce_GHRlD1",
    "outputId": "2c3092eb-f8b3-4b6d-f66c-326a291851c3"
   },
   "outputs": [],
   "source": [
    "print(citations_df.Citations.min())\n",
    "print(citations_df.Citations.max())\n",
    "\n",
    "print(citations_df[citations_df[\"Citations\"] >= citations_df.Citations.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most cited paper is called \"Distinctive Image Features from Scale-Invariant Keypoints with 35,541 citations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING ON ISSUE #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fosDict={}\n",
    "\n",
    "for fields in citations_df[\"Field of Study\"]:\n",
    "  fieldsList=fields.split(\", \")\n",
    "  for field in fieldsList:\n",
    "    # print(field)\n",
    "    fosDict[field] = fosDict.get(field, 0) + 1\n",
    "  # print(\"---------\")\n",
    "\n",
    "print(fosDict)\n",
    "\n",
    "\n",
    "fieldsKeys=list(fosDict.keys())\n",
    "fieldsValues=[fosDict.get(field) for field in fieldsKeys]\n",
    "\n",
    "fos_df = pd.DataFrame({\n",
    "    \"Field\": fieldsKeys,\n",
    "    \"Frequency\": fieldsValues\n",
    "})\n",
    "\n",
    "fos_df.set_index(\"Field\", inplace=True)\n",
    "\n",
    "fos_df = fos_df.sort_values(\"Frequency\", ascending=False)\n",
    "fos_df = fos_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out Top 5 most common fields\n",
    "print(fos_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out 5 least common fields\n",
    "print(fos_df.tail(24391))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lowest_freq_field = 0\n",
    "for key in fosDict:\n",
    "    if fosDict.get(key) == 1:\n",
    "        num_lowest_freq_field += 1\n",
    "\n",
    "print(num_lowest_freq_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24390 fields of study are seen only once in the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the “Field of Study” column to create separate rows for each field\n",
    "citations_df = citations_df.explode(\"Field of Study\")\n",
    "\n",
    "# Group citations dataset by the “Field of Study” column\n",
    "grouped = citations_df.groupby(\"Field of Study\")\n",
    "\n",
    "# Initialize a dictionary to store the top 5 influential figures in each field\n",
    "top_influential_figures = {}\n",
    "\n",
    "# Iterate over each group\n",
    "for field, group in grouped:\n",
    "    # Initialize a dictionary to store the cumulative citations for each author\n",
    "    author_citations = {}\n",
    "\n",
    "    # Iterate over each row in the group\n",
    "    for index, row in group.iterrows():\n",
    "        # Split authors by comma and iterate over them\n",
    "        authors = row[\"Authors\"].split(\", \")\n",
    "\n",
    "        # Calculate cumulative citations for each author\n",
    "        for author in authors:\n",
    "            author_citations[author] = author_citations.get(author, 0) + row[\"Citations\"]\n",
    "\n",
    "    # Sort authors by their cumulative citations in descending order\n",
    "    sorted_authors = sorted(author_citations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select the top 5 authors with the highest cumulative citations\n",
    "    top_influential_figures[field] = sorted_authors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in top_influential_figures.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 3: \n",
    "The fields with the top 5 biggest growth in papers being published. This is simply the increase of published papers over a year, or 5 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of papers that were published each year starting from 1800\n",
    "grouped_df = citations_df.groupby(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary where key=Year and value=Dictionary of Field of Study Frequency for that year\n",
    "year_fos_dict = {}\n",
    "for year in grouped_df.indices.keys():\n",
    "    year_fos_list = grouped_df.get_group(year)[\"Field of Study\"].tolist()\n",
    "    temp_list = []\n",
    "    for row in year_fos_list:\n",
    "        temp_list.extend(row.split(\", \"))\n",
    "\n",
    "    fos_dict = {}\n",
    "    for fos in temp_list:\n",
    "        fos_dict[fos] = fos_dict.get(fos, 0) + 1\n",
    "\n",
    "    year_fos_dict[year] = fos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look inside the year_fos_dict\n",
    "for year, fos in year_fos_dict.items():\n",
    "    print(year, fos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFields = fos_df.head(5)[\"Field\"].tolist()\n",
    "# topFields = [\"Computer science\", \"Artificial intelligence\", \"Mathematics\", \"Machine learning\", \"Mathematical optimization\"]\n",
    "\n",
    "# Find the number of citations at a year for each of the top 5 fields\n",
    "# by making a list whose length is the range between the smallest year in\n",
    "# citations_df and the largest year in citations_df. \n",
    "# For this list, index 0=the lowest year in citations_df.\n",
    "fos_freq_year_dict = {}\n",
    "for fos in topFields:\n",
    "    fos_freq_year = [] # Field of study frequency for that year\n",
    "    for year in range(citations_df.Year.min(), citations_df.Year.max() + 1):\n",
    "        if year not in list(year_fos_dict.keys()):\n",
    "            fos_freq_year.append(0)\n",
    "        else:\n",
    "            if fos in year_fos_dict[year]:\n",
    "                fos_freq_year.append(year_fos_dict[year][fos])\n",
    "            else:\n",
    "                fos_freq_year.append(0)\n",
    "    fos_freq_year_dict[fos] = fos_freq_year\n",
    "\n",
    "print(fos_freq_year_dict)\n",
    "# print(fos_freq_year_dict.keys())\n",
    "# print(fos_freq_year_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if outputs look good\n",
    "print(len(fos_freq_year_dict[\"Computer science\"]))\n",
    "print(len(fos_freq_year_dict[\"Artificial intelligence\"]))\n",
    "print(len(fos_freq_year_dict[\"Mathematics\"]))\n",
    "print(len(fos_freq_year_dict[\"Machine learning\"]))\n",
    "print(len(fos_freq_year_dict[\"Mathematical optimization\"]))\n",
    "\n",
    "print(sum(fos_freq_year_dict[\"Computer science\"]))\n",
    "print(sum(fos_freq_year_dict[\"Artificial intelligence\"]))\n",
    "print(sum(fos_freq_year_dict[\"Mathematics\"]))\n",
    "print(sum(fos_freq_year_dict[\"Machine learning\"]))\n",
    "print(sum(fos_freq_year_dict[\"Mathematical optimization\"]))\n",
    "\n",
    "print(fos_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line chart starting from the year 1950 and \n",
    "# going to the maximum year in citations_df minus 2 year \n",
    "# (i.e 2018 because at 2020, it looks like graph just dips off)\n",
    "years = [i for i in range(1950, citations_df.Year.max()-1)]\n",
    "\n",
    "for key in fos_freq_year_dict:\n",
    "  plt.plot(years, fos_freq_year_dict[key][150:-2], label=key)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title('Num Mentions of a Field Per Year')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the top 5 most popular fields, it seems that they started experiencing large growths around 1990."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1ooexgbmter3jd6lXQwMOw7VGUw6qwM6c",
     "timestamp": 1712257476240
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
