{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG_KpSM1FlQv"
   },
   "source": [
    "# COMP440 Collective Intelligence Team Nostradami Final Project: Citation Networks\n",
    "\n",
    "## Team Nostradami is: Gugo Babayan, Eddie Chen, Nick Duncan, and Rory Donaghy\n",
    "___\n",
    "### What dataset are we working with?\n",
    "AMiner is a project from Chinese university, Beijing Jiaotong University, by researchers Huaiyu Wan, Yutao Zhang, Jing Zhang, and Jie Tang. The project was first published in 2019 via MIT Press Direct, which can be found [here](https://direct.mit.edu/dint/article/1/1/58/9974/AMiner-Search-and-Mining-of-Academic-Social). We're using v12 which we're downloading from Kaggle ([Dataset Link](https://www.kaggle.com/datasets/mathurinache/citation-network-dataset/data?select=dblp.v12.json)), as the latest version (v14) is difficult to access due to the data servers being located in China.\n",
    "\n",
    "### How was the dataset collected?\n",
    "AMiner's scientific publication citation network was created by scraping sources from dblp, acm, and mag. How the network was constructed is outlined in the paper linked above.\n",
    "\n",
    "### For what purpose was the dataset collected?\n",
    "This dataset was created for strictly academic research purposes, and is offered for free through the projects website for data scientists to analyze\n",
    "___\n",
    "## To Run This Project, First Reference The README.md and Ensure You Have A Copy of Our Cleaned Data (named indexed_data.csv) Which Can Be Created With clean_data.py Or Downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM1Ny3K_17q8"
   },
   "outputs": [],
   "source": [
    "citations_df = pd.read_csv('unindexed_data.csv')\n",
    "\n",
    "citations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover Dataframe From CSV\n",
    "citations_df = citations_df.dropna(subset=[\"Document Type\"])\n",
    "citations_df = citations_df.dropna(subset=[\"Field of Study\"])\n",
    "citations_df[\"Field of Study\"] = citations_df[\"Field of Study\"].apply(lambda fields: fields.split(\", \"))\n",
    "citations_df[\"Authors\"] = citations_df[\"Authors\"].apply(lambda fields: fields.split(\", \"))\n",
    "citations_df[\"References\"] = citations_df[\"References\"].apply(lambda x: x.split(\", \") if type(x)==str else list())\n",
    "print(citations_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns are Series data types\n",
    "print(citations_df.Year.min())\n",
    "print(citations_df.Year.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'citations_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Papers written between 1800 (inclusive) and 1899 (inclusive)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcitations_df\u001b[49m[(citations_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1800\u001b[39m) \u001b[38;5;241m&\u001b[39m (citations_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1900\u001b[39m)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'citations_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Papers written between 1800 (inclusive) and 1899 (inclusive)\n",
    "print(citations_df[(citations_df[\"Year\"] >= 1800) & (citations_df[\"Year\"] < 1900)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papers written between 1900 (inclusive) and 1999 (inclusive)\n",
    "print(citations_df[(citations_df[\"Year\"] >= 1900) & (citations_df[\"Year\"] < 1999)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papers written past 2000 (inclusive)\n",
    "print(citations_df[(citations_df[\"Year\"] >= 2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13719,
     "status": "ok",
     "timestamp": 1712638784951,
     "user": {
      "displayName": "Eddie Chen",
      "userId": "17886336257218875792"
     },
     "user_tz": 300
    },
    "id": "GeZSJvuUL_5C",
    "outputId": "bebf4c6e-acc4-4500-f3d2-e399cf7bb1b3"
   },
   "outputs": [],
   "source": [
    "print(len(citations_df.Title.unique()))\n",
    "print(\"There are \" + str(citations_df.shape[0] - len(citations_df.Title.unique())) + \" papers that share the same title\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddkfkZvuOA-y"
   },
   "source": [
    "Of the 3,277,181 papers in the dataset, there are only 3,232,994 unique titles. This means that 44,187 papers share their title with another paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_df.loc[citations_df[citations_df[\"Citations\"] >= citations_df.Citations.max()].index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1712639760886,
     "user": {
      "displayName": "Eddie Chen",
      "userId": "17886336257218875792"
     },
     "user_tz": 300
    },
    "id": "4_1Ce_GHRlD1",
    "outputId": "2c3092eb-f8b3-4b6d-f66c-326a291851c3"
   },
   "outputs": [],
   "source": [
    "print(citations_df.Citations.min())\n",
    "print(citations_df.Citations.max())\n",
    "\n",
    "print(citations_df[citations_df[\"Citations\"] >= citations_df.Citations.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most cited paper is called \"Distinctive Image Features from Scale-Invariant Keypoints with 35,541 citations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Most Common Field of Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Create frequency dictionary for the \"Field of Study\" column\n",
    "# of the citations dataframe, citations_df.\n",
    "# ---------------------------------------------------------------------------\n",
    "fosDict={}\n",
    "\n",
    "for fields in citations_df[\"Field of Study\"]:\n",
    "  for field in fields:\n",
    "    fosDict[field] = fosDict.get(field, 0) + 1\n",
    "\n",
    "\n",
    "fieldsKeys=list(fosDict.keys())\n",
    "fieldsValues=[fosDict.get(field) for field in fieldsKeys]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Create a Field of Study Dataframe, fos_df.\n",
    "# ------------------------------------------------------------\n",
    "fos_df = pd.DataFrame({\n",
    "    \"Field\": fieldsKeys,\n",
    "    \"Frequency\": fieldsValues\n",
    "})\n",
    "\n",
    "fos_df.set_index(\"Field\", inplace=True)\n",
    "\n",
    "fos_df = fos_df.sort_values(\"Frequency\", ascending=False)\n",
    "fos_df = fos_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out Top 5 most common fields\n",
    "print(fos_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Finding the number of fields of study that are only mentioned once.\n",
    "# ---------------------------------------------------------------------------\n",
    "num_lowest_freq_field = 0\n",
    "for key in fosDict:\n",
    "    if fosDict.get(key) == 1:\n",
    "        num_lowest_freq_field += 1\n",
    "\n",
    "print(num_lowest_freq_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Print out the least common fields.\n",
    "# ---------------------------------------------------------------------------\n",
    "print(fos_df.tail(num_lowest_freq_field + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24390 fields of study are seen only once in the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Top Authors In Each Field of Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Create A Dictionary Containing The Top 20 Authors of Each Field In Dataset\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "citations_df = citations_df.explode(\"Field of Study\")\n",
    "grouped = citations_df.groupby(\"Field of Study\")\n",
    "\n",
    "top_influential_figures = {}\n",
    "\n",
    "for field, group in grouped:\n",
    "    author_citations = {}\n",
    "    \n",
    "    for index, row in group.iterrows():\n",
    "        authors = row[\"Authors\"].split(\", \")\n",
    "        \n",
    "        for author in authors:\n",
    "            author_citations[author] = author_citations.get(author, 0) + row[\"Citations\"]\n",
    "            \n",
    "    sorted_authors = sorted(author_citations.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_influential_figures[field] = sorted_authors[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_influential_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate Growth In Fields Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Create a line graph of the top 5 fields of study in the citations \n",
    "# dataframe (citations_df) where the x-axis represents \"Year\" and the\n",
    "# y-axis represents the \"Frequency\" that we've seen the field of study\n",
    "# throughout the entire citations dataframe.\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Create a dataframe of papers that were published each year starting from 1800\n",
    "grouped_df = citations_df.groupby(\"Year\")\n",
    "# Create dictionary where key=Year and value=Dictionary of Field of Study Frequency for that year\n",
    "year_fos_dict = {}\n",
    "for year in grouped_df.indices.keys():\n",
    "    year_fos_list = grouped_df.get_group(year)[\"Field of Study\"].tolist()\n",
    "    temp_list = []\n",
    "    for fields in year_fos_list:\n",
    "        temp_list.extend(fields)\n",
    "\n",
    "    fos_dict = {}\n",
    "    for fos in temp_list:\n",
    "        fos_dict[fos] = fos_dict.get(fos, 0) + 1\n",
    "\n",
    "    year_fos_dict[year] = fos_dict\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "topFields = fos_df.head(5)[\"Field\"].tolist()\n",
    "\n",
    "# Find the number of citations at a year for each of the top 5 fields\n",
    "# by making a list whose length is the range between the smallest year in\n",
    "# citations_df and the largest year in citations_df. \n",
    "# For this list, index 0=the lowest year in citations_df.\n",
    "fos_freq_year_dict = {}\n",
    "for fos in topFields:\n",
    "    fos_freq_year = [] # Field of study frequency for that year\n",
    "    for year in range(citations_df.Year.min(), citations_df.Year.max() + 1):\n",
    "        if year not in list(year_fos_dict.keys()):\n",
    "            fos_freq_year.append(0)\n",
    "        else:\n",
    "            if fos in year_fos_dict[year]:\n",
    "                fos_freq_year.append(year_fos_dict[year][fos])\n",
    "            else:\n",
    "                fos_freq_year.append(0)\n",
    "    fos_freq_year_dict[fos] = fos_freq_year\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Create a line chart starting from the year 1950 and \n",
    "# going to the maximum year in citations_df minus 2 year \n",
    "# (i.e 2018 because at 2020, it looks like graph just dips off)\n",
    "# ----------------------------------------------------------------\n",
    "years = [i for i in range(1950, citations_df.Year.max()-1)]\n",
    "\n",
    "for key in fos_freq_year_dict:\n",
    "  plt.plot(years, fos_freq_year_dict[key][150:-2], label=key)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title('Num Mentions of a Field Per Year')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIND ORIGINAL PAPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = final_df[:5]\n",
    "print(small_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = final_df.references_column.isna()\n",
    "masked_df = final_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(masked_df[masked_df[\"Document Type\"] == \"Journal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_df[\"Document Type\"]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=masked_df, x=\"Document Type\")\n",
    "plt.title(\"Distribution of Original Paper's Document Types\")\n",
    "plt.xlabel(\"Document Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=final_df, x=\"Document Type\")\n",
    "plt.title(\"Distribution of All Paper's Document Types\")\n",
    "plt.xlabel(\"Document Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fos_df.head(20))\n",
    "topFields = fos_df[\"Field\"].to_numpy()[1:20]\n",
    "print(len(topFields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate How CS Has Interacted With Other Fields Over Time By Showing Growth of Fields Associated With CS In Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Create a line graph tracking the times we've seen a field of study \n",
    "# for the top 19 fields (excluding \"Computer science\") over time for papers\n",
    "# that have both the fields of study \"Computer science\" and one of or more\n",
    "# fields from the top 19 fields of study in the citations dataframe (citations_df) \n",
    "# where the x-axis represents \"Year\" and the y-axis represents the \"Frequency\"\n",
    "# that we've seen the field of study throughout the entire citations dataframe.\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Create dictionary where key=Year and value=Dictionary of Field of Study Frequency for that year\n",
    "year_fos_dict = {}\n",
    "for year in grouped_df.indices.keys():\n",
    "    year_fos_list = grouped_df.get_group(year)[\"Field of Study\"].to_numpy()\n",
    "    temp_list = []\n",
    "    for fields in year_fos_list:\n",
    "        if (not set(topFields).isdisjoint(set(fields)) and \"Computer science\" in set(fields)):\n",
    "            temp_list.extend(fields)\n",
    "\n",
    "    fos_dict = {}\n",
    "    for fos in temp_list:\n",
    "        fos_dict[fos] = fos_dict.get(fos, 0) + 1\n",
    "\n",
    "    year_fos_dict[year] = fos_dict\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# topFields = [\"Artificial intelligence\", \"Mathematics\", \"Machine learning\", \"Mathematical optimization\", ... , \"Multimedia\"]\n",
    "\n",
    "# Find the number of citations at a year for each of the top 19 fields for \n",
    "# papers that have the \"Computer science\" field and one or more of the top 19 fields\n",
    "# by making a list whose length is the range between the smallest year in\n",
    "# citations_df and the largest year in citations_df. \n",
    "# For this list, index 0=the lowest year in citations_df.\n",
    "fos_freq_year_dict = {}\n",
    "for fos in topFields:\n",
    "    fos_freq_year = [] # Field of study frequency for that year\n",
    "    for year in range(citations_df.Year.min(), citations_df.Year.max() + 1):\n",
    "        if year not in list(year_fos_dict.keys()):\n",
    "            fos_freq_year.append(0)\n",
    "        else:\n",
    "            if fos in year_fos_dict[year]:\n",
    "                fos_freq_year.append(year_fos_dict[year][fos])\n",
    "            else:\n",
    "                fos_freq_year.append(0)\n",
    "    fos_freq_year_dict[fos] = fos_freq_year\n",
    "\n",
    "# print(fos_freq_year_dict)\n",
    "# print(fos_freq_year_dict.keys())\n",
    "# print(fos_freq_year_dict.values())\n",
    "# ----------------------------------------------------------------\n",
    "# Create a line chart starting from the year 1950 and \n",
    "# going to the maximum year in citations_df minus 2 year \n",
    "# (i.e 2018 because at 2020, it looks like graph just dips off)\n",
    "years = [i for i in range(1950, citations_df.Year.max()-1)]\n",
    "plt.figure(figsize=(100,50))\n",
    "plt.rcParams[\"font.size\"] = 50\n",
    "plt.rcParams[\"lines.linewidth\"] = 10\n",
    "\n",
    "for key in fos_freq_year_dict:\n",
    "  plt.plot(years, fos_freq_year_dict[key][150:-2], label=key)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title('Num Mentions of a Field Pair Per Year')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCOMPLETE AS OF PROJECT DEADLINE: Show How Authors Inetract With Each Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Removes papers that are not part of the CS Field and do not contain a \n",
    "# secondary field that is a part of the top 20 fields\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def trim_non_top_fields(fos_list):\n",
    "  if not set(fos_list).isdisjoint(set(top_19)) and \"Computer science\" in set(fos_list):\n",
    "    trimmed = [x for x in fos_list if x in top_fields]\n",
    "    if trimmed.index(\"Computer science\") != 0:\n",
    "      trimmed.insert(0, trimmed.pop(trimmed.index(\"Computer science\")))\n",
    "    return trimmed\n",
    "  return np.NaN\n",
    "\n",
    "citations_df['Field of Study'] = citations_df['Field of Study'].apply(lambda x: trim_non_top_fields(x))\n",
    "\n",
    "citations_df = citations_df.dropna(subset=[\"Field of Study\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Creates a dataframe that contains edge relationships between authors, WIP\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "citations_df = citations_df.reset_index() # Since I'm relying on the index here, I don't want gaps\n",
    "authors = list(set([x for xs in citations_df[\"Authors\"].to_list() for x in xs]))\n",
    "\n",
    "# Create Lookup tables for easy access of data location\n",
    "authors_lookup_table = {k: v for v, k in enumerate(authors)}\n",
    "id_lookup_table = {k: v for v, k in enumerate(citations_df[\"ID\"].to_list())}\n",
    "\n",
    "author_network_df = pd.DataFrame({\"A\": np.array(authors)})\n",
    "author_network_df[\"B\"] = np.empty((len(author_network_df), 0)).tolist()\n",
    "\n",
    "# Iterates through papers and assigns references authors (A) each authors citation list (B)\n",
    "for index, row in citations_df.itterrows():\n",
    "  authors = row[\"Authors\"]\n",
    "  references = row[\"References\"]\n",
    "  for author in authors:\n",
    "    author_index = authors_lookup_table.get(author, -1)\n",
    "    if author_index >= 0:\n",
    "      for ref in references:\n",
    "        paper_index = id_lookup_table.get(ref, -1)\n",
    "        if paper_index >= 0:\n",
    "          paper = citations_df.iloc[paper_index]\n",
    "          author_network_df.iloc[author_index][\"B\"] = author_network_df.iloc[author_index][\"B\"] + set(paper[\"Authors\"])\n",
    "\n",
    "# Explode to make them single edge relationships\n",
    "exploded = author_network_df.explode(\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(exploded['A'])\n",
    "G.add_nodes_from(exploded['B'])\n",
    "edges = [(row['A'], row['B']) for index, row in exploded.iterrows()]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1ooexgbmter3jd6lXQwMOw7VGUw6qwM6c",
     "timestamp": 1712257476240
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
